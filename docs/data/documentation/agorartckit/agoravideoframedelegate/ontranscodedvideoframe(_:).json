{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"optional"},{"kind":"text","text":" "},{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onTranscodedVideoFrame"},{"kind":"text","text":"("},{"kind":"externalParam","text":"_"},{"kind":"text","text":" "},{"kind":"internalParam","text":"videoFrame"},{"kind":"text","text":": "},{"kind":"typeIdentifier","identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame","text":"AgoraOutputVideoFrame"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"languages":["swift"],"platforms":["iOS"]}]},{"kind":"parameters","parameters":[{"name":"videoFrame","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The video frame. See AgoraOutputVideoFrame .The"},{"type":"text","text":" "},{"type":"text","text":"default value of the video frame data format obtained through this callback"},{"type":"text","text":" "},{"type":"text","text":"is as follows:iOS: cvPixelBuffer"}]}]}]},{"kind":"content","content":[{"anchor":"return-value","level":2,"type":"heading","text":"Return Value"},{"type":"paragraph","inlineContent":[{"type":"text","text":"When the video processing mode is"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFrameProcessModeReadOnly : YES : Reserved for future use. NO :"},{"type":"text","text":" "},{"type":"text","text":"Reserved for future use. When the video processing mode is"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFrameProcessModeReadWrite : YES : Sets the SDK to receive the video"},{"type":"text","text":" "},{"type":"text","text":"frame. NO : Sets the SDK to discard the video frame."}]}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"variants":[{"paths":["\/documentation\/agorartckit\/agoravideoframedelegate\/ontranscodedvideoframe(_:)"],"traits":[{"interfaceLanguage":"swift"}]},{"paths":["\/documentation\/agorartckit\/agoravideoframedelegate\/ontranscodedvideoframe(_:)"],"traits":[{"interfaceLanguage":"occ"}]}],"identifier":{"url":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onTranscodedVideoFrame(_:)","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Gets the video data captured from the screen before encoding."},{"type":"text","text":" "},{"type":"text","text":"After you successfully register the video frame observer, the SDK triggers"},{"type":"text","text":" "},{"type":"text","text":"this callback each time it receives a video frame. In this callback, you can"},{"type":"text","text":" "},{"type":"text","text":"get the video data captured from the screen before encoding and then process"},{"type":"text","text":" "},{"type":"text","text":"the data according to your particular scenarios.After processing, you can"},{"type":"text","text":" "},{"type":"text","text":"send the processed video data back to the SDK in this callback.To get the"},{"type":"text","text":" "},{"type":"text","text":"video data captured from the second screen before encoding, you need to set"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFramePositionPreEncoder (1 << 2) as a frame position through"},{"type":"text","text":" "},{"type":"text","text":"getObservedFramePosition .The video data that this callback gets has been"},{"type":"text","text":" "},{"type":"text","text":"preprocessed, with its content cropped and rotated, and the image"},{"type":"text","text":" "},{"type":"text","text":"enhanced.This callback does not support sending processed RGBA video data"},{"type":"text","text":" "},{"type":"text","text":"back to the SDK."}],"kind":"symbol","metadata":{"navigatorTitle":[{"kind":"identifier","text":"onTranscodedVideoFrame:"}],"role":"symbol","title":"onTranscodedVideoFrame(_:)","roleHeading":"Instance Method","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onTranscodedVideoFrame"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"symbolKind":"method","externalID":"c:objc(pl)AgoraVideoFrameDelegate(im)onTranscodedVideoFrame:","required":true,"modules":[{"name":"AgoraRtcKit"}]},"hierarchy":{"paths":[["doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate"]]},"references":{"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate":{"role":"symbol","title":"AgoraVideoFrameDelegate","fragments":[{"kind":"keyword","text":"protocol"},{"kind":"text","text":" "},{"kind":"identifier","text":"AgoraVideoFrameDelegate"}],"abstract":[{"type":"text","text":"The IVideoFrameObserver class."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}],"url":"\/documentation\/agorartckit\/agoravideoframedelegate"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/onTranscodedVideoFrame(_:)":{"navigatorTitle":[{"kind":"identifier","text":"onTranscodedVideoFrame:"}],"role":"symbol","title":"onTranscodedVideoFrame(_:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onTranscodedVideoFrame"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Gets the video data captured from the screen before encoding."},{"type":"text","text":" "},{"type":"text","text":"After you successfully register the video frame observer, the SDK triggers"},{"type":"text","text":" "},{"type":"text","text":"this callback each time it receives a video frame. In this callback, you can"},{"type":"text","text":" "},{"type":"text","text":"get the video data captured from the screen before encoding and then process"},{"type":"text","text":" "},{"type":"text","text":"the data according to your particular scenarios.After processing, you can"},{"type":"text","text":" "},{"type":"text","text":"send the processed video data back to the SDK in this callback.To get the"},{"type":"text","text":" "},{"type":"text","text":"video data captured from the second screen before encoding, you need to set"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFramePositionPreEncoder (1 << 2) as a frame position through"},{"type":"text","text":" "},{"type":"text","text":"getObservedFramePosition .The video data that this callback gets has been"},{"type":"text","text":" "},{"type":"text","text":"preprocessed, with its content cropped and rotated, and the image"},{"type":"text","text":" "},{"type":"text","text":"enhanced.This callback does not support sending processed RGBA video data"},{"type":"text","text":" "},{"type":"text","text":"back to the SDK."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onTranscodedVideoFrame(_:)","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/ontranscodedvideoframe(_:)"},"doc://AgoraRtcKit/documentation/AgoraRtcKit":{"role":"collection","title":"AgoraRtcKit","abstract":[{"type":"text","text":"Summary"}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit","kind":"symbol","type":"topic","url":"\/documentation\/agorartckit"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraOutputVideoFrame":{"role":"symbol","title":"AgoraOutputVideoFrame","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AgoraOutputVideoFrame"}],"abstract":[{"type":"text","text":"Configurations of the video frame."},{"type":"text","text":" "},{"type":"text","text":"Note that the buffer provides a pointer to a pointer. This interface cannot"},{"type":"text","text":" "},{"type":"text","text":"modify the pointer of the buffer, but it can modify the content of the"},{"type":"text","text":" "},{"type":"text","text":"buffer."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraOutputVideoFrame","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AgoraOutputVideoFrame"}],"url":"\/documentation\/agorartckit\/agoraoutputvideoframe"}},"variantOverrides":[{"patch":[{"op":"replace","path":"\/identifier\/interfaceLanguage","value":"occ"},{"op":"replace","path":"\/metadata\/roleHeading","value":"Instance Method"},{"op":"replace","path":"\/metadata\/title","value":"onTranscodedVideoFrame:"},{"op":"replace","path":"\/metadata\/symbolKind","value":"method"},{"op":"replace","path":"\/metadata\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onTranscodedVideoFrame:"}]},{"op":"add","path":"\/topicSections","value":null},{"op":"add","path":"\/relationshipsSections","value":null},{"op":"add","path":"\/seeAlsoSections","value":null},{"op":"replace","path":"\/primaryContentSections\/0","value":{"kind":"declarations","declarations":[{"tokens":[{"kind":"text","text":"- ("},{"kind":"typeIdentifier","text":"BOOL","preciseIdentifier":"c:@T@BOOL"},{"kind":"text","text":") "},{"kind":"identifier","text":"onTranscodedVideoFrame:"},{"kind":"text","text":"("},{"kind":"typeIdentifier","identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame","text":"AgoraOutputVideoFrame"},{"kind":"text","text":" *) "},{"kind":"internalParam","text":"videoFrame"},{"kind":"text","text":";"}],"languages":["occ"],"platforms":["iOS"]}]}},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate\/title","value":"AgoraVideoFrameDelegate"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate\/fragments","value":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onTranscodedVideoFrame(_:)\/title","value":"onTranscodedVideoFrame:"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onTranscodedVideoFrame(_:)\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onTranscodedVideoFrame:"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraOutputVideoFrame\/title","value":"AgoraOutputVideoFrame"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraOutputVideoFrame\/fragments","value":[{"kind":"identifier","text":"AgoraOutputVideoFrame"}]}],"traits":[{"interfaceLanguage":"occ"}]}]}