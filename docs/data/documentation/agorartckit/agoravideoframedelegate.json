{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"protocol"},{"kind":"text","text":" "},{"kind":"identifier","text":"AgoraVideoFrameDelegate"},{"kind":"text","text":" : "},{"kind":"typeIdentifier","text":"NSObjectProtocol","preciseIdentifier":"c:objc(pl)NSObject"}],"languages":["swift"],"platforms":["iOS"]}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"variants":[{"paths":["\/documentation\/agorartckit\/agoravideoframedelegate"],"traits":[{"interfaceLanguage":"swift"}]},{"paths":["\/documentation\/agorartckit\/agoravideoframedelegate"],"traits":[{"interfaceLanguage":"occ"}]}],"relationshipsSections":[{"identifiers":["doc:\/\/AgoraRtcKit\/objc(pl)NSObject"],"kind":"relationships","title":"Inherits From","type":"inheritsFrom"}],"identifier":{"url":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"The IVideoFrameObserver class."}],"kind":"symbol","metadata":{"fragments":[{"kind":"keyword","text":"protocol"},{"kind":"text","text":" "},{"kind":"identifier","text":"AgoraVideoFrameDelegate"}],"title":"AgoraVideoFrameDelegate","roleHeading":"Protocol","role":"symbol","symbolKind":"protocol","externalID":"c:objc(pl)AgoraVideoFrameDelegate","modules":[{"name":"AgoraRtcKit"}],"navigatorTitle":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}]},"hierarchy":{"paths":[["doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit"]]},"topicSections":[{"title":"Instance Methods","identifiers":["doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getMirrorApplied()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getObservedFramePosition()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getRotationApplied()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getVideoFormatPreference()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getVideoFrameProcessMode()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onCapture(_:sourceType:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onMediaPlayerVideoFrame(_:mediaPlayerId:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onPreEncode(_:sourceType:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onRenderVideoFrame(_:uid:channelId:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onTranscodedVideoFrame(_:)"]}],"references":{"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/getObservedFramePosition()":{"role":"symbol","title":"getObservedFramePosition()","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"getObservedFramePosition"},{"kind":"text","text":"() -> "},{"kind":"typeIdentifier","text":"AgoraVideoFramePosition","preciseIdentifier":"c:@E@AgoraVideoFramePosition"}],"abstract":[{"type":"text","text":"Sets the frame position for the video observer."},{"type":"text","text":" "},{"type":"text","text":"After successfully registering the video data observer, the SDK uses this"},{"type":"text","text":" "},{"type":"text","text":"callback to determine whether to trigger onCaptureVideoFrame ,"},{"type":"text","text":" "},{"type":"text","text":"onRenderVideoFrame and onPreEncodeVideoFrame callback at each specific video"},{"type":"text","text":" "},{"type":"text","text":"frame processing position, so that you can observe the locally collected"},{"type":"text","text":" "},{"type":"text","text":"video data, the video data sent by the remote end, and the video data before"},{"type":"text","text":" "},{"type":"text","text":"encoding. You can set one or more positions you need to observe by modifying"},{"type":"text","text":" "},{"type":"text","text":"the return value according to your"},{"type":"text","text":" "},{"type":"text","text":"scenario:AgoraVideoFramePositionPostCapture(1 << 0): The position after"},{"type":"text","text":" "},{"type":"text","text":"capturing the video data, which corresponds to the onCaptureVideoFrame"},{"type":"text","text":" "},{"type":"text","text":"callback.AgoraVideoFramePositionPreRenderer(1 << 1): The position of the"},{"type":"text","text":" "},{"type":"text","text":"received remote video data before rendering, which corresponds to the"},{"type":"text","text":" "},{"type":"text","text":"onRenderVideoFrame callback.AgoraVideoFramePositionPreEncoder(1 << 2): The"},{"type":"text","text":" "},{"type":"text","text":"position before encoding the video data, which corresponds to the"},{"type":"text","text":" "},{"type":"text","text":"onPreEncodeVideoFrame callback.Use ‘|’ (the OR operator) to observe multiple"},{"type":"text","text":" "},{"type":"text","text":"frame positions.This callback observes AgoraVideoFramePositionPostCapture(1"},{"type":"text","text":" "},{"type":"text","text":"<< 0) and AgoraVideoFramePositionPreRenderer(1 << 1) by default.To conserve"},{"type":"text","text":" "},{"type":"text","text":"system resources, you can reduce the number of frame positions that you want"},{"type":"text","text":" "},{"type":"text","text":"to observe.When the video processing mode is"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFrameProcessModeReadWrite and the observation position is set to"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFramePositionPreEncoder | AgoraVideoFramePositionPostCapture, the"},{"type":"text","text":" "},{"type":"text","text":"getMirrorApplied does not take effect; you need to modify the video"},{"type":"text","text":" "},{"type":"text","text":"processing mode or the position of the observer."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getObservedFramePosition()","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"getObservedFramePosition"}],"url":"\/documentation\/agorartckit\/agoravideoframedelegate\/getobservedframeposition()"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/getMirrorApplied()":{"navigatorTitle":[{"kind":"identifier","text":"getMirrorApplied"}],"role":"symbol","title":"getMirrorApplied()","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"getMirrorApplied"},{"kind":"text","text":"() -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Occurs each time the SDK receives a video frame and prompts you whether or"},{"type":"text","text":" "},{"type":"text","text":"not to mirror the captured video. If the video data you want to obtain is a"},{"type":"text","text":" "},{"type":"text","text":"mirror image of the original video, you need to register this callback when"},{"type":"text","text":" "},{"type":"text","text":"calling setVideoFrameDelegate . After you successfully register the video"},{"type":"text","text":" "},{"type":"text","text":"frame observer, the SDK triggers this callback each time it receives a video"},{"type":"text","text":" "},{"type":"text","text":"frame. You need to set whether or not to mirror the video frame in the return"},{"type":"text","text":" "},{"type":"text","text":"value of this callback.This function only supports video data in RGBA and"},{"type":"text","text":" "},{"type":"text","text":"YUV420.Both this method and the setVideoEncoderConfiguration method support"},{"type":"text","text":" "},{"type":"text","text":"setting the mirroring effect. Agora recommends that you only choose one"},{"type":"text","text":" "},{"type":"text","text":"method to set it up. Using both methods at the same time causes the mirroring"},{"type":"text","text":" "},{"type":"text","text":"effect to overlap, which causes the mirroring settings to fail."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getMirrorApplied()","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/getmirrorapplied()"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/getVideoFrameProcessMode()":{"navigatorTitle":[{"kind":"identifier","text":"getVideoFrameProcessMode"}],"role":"symbol","title":"getVideoFrameProcessMode()","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"getVideoFrameProcessMode"},{"kind":"text","text":"() -> "},{"kind":"typeIdentifier","text":"AgoraVideoFrameProcessMode","preciseIdentifier":"c:@E@AgoraVideoFrameProcessMode"}],"abstract":[{"type":"text","text":"Occurs each time the SDK receives a video frame and prompts you to set the"},{"type":"text","text":" "},{"type":"text","text":"process mode of the video frame. After you successfully register the video"},{"type":"text","text":" "},{"type":"text","text":"frame observer, the SDK triggers this callback each time it receives a video"},{"type":"text","text":" "},{"type":"text","text":"frame. You need to set your preferred process mode in the return value of"},{"type":"text","text":" "},{"type":"text","text":"this callback."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getVideoFrameProcessMode()","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/getvideoframeprocessmode()"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/onCapture(_:sourceType:)":{"navigatorTitle":[{"kind":"identifier","text":"onCaptureVideoFrame:sourceType:"}],"role":"symbol","title":"onCapture(_:sourceType:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onCapture"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":", "},{"kind":"externalParam","text":"sourceType"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"AgoraVideoSourceType","preciseIdentifier":"c:@E@AgoraVideoSourceType"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Occurs each time the SDK receives a video frame captured by the local camera."},{"type":"text","text":" "},{"type":"text","text":"After you successfully register the video frame observer, the SDK triggers"},{"type":"text","text":" "},{"type":"text","text":"this callback each time it receives a video frame. In this callback, you can"},{"type":"text","text":" "},{"type":"text","text":"get the video data captured by the local camera. You can then pre-process the"},{"type":"text","text":" "},{"type":"text","text":"data according to your scenarios.After pre-processing, you can send the"},{"type":"text","text":" "},{"type":"text","text":"processed video data back to the SDK through this callback.The video data"},{"type":"text","text":" "},{"type":"text","text":"that this callback gets has not been pre-processed, and is not watermarked,"},{"type":"text","text":" "},{"type":"text","text":"cropped, rotated or beautified.If the video data type you get is RGBA, the"},{"type":"text","text":" "},{"type":"text","text":"SDK does not support processing the data of the alpha channel."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onCapture(_:sourceType:)","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/oncapture(_:sourcetype:)"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate":{"role":"symbol","title":"AgoraVideoFrameDelegate","fragments":[{"kind":"keyword","text":"protocol"},{"kind":"text","text":" "},{"kind":"identifier","text":"AgoraVideoFrameDelegate"}],"abstract":[{"type":"text","text":"The IVideoFrameObserver class."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}],"url":"\/documentation\/agorartckit\/agoravideoframedelegate"},"doc://AgoraRtcKit/objc(pl)NSObject":{"type":"unresolvable","title":"NSObject","identifier":"doc:\/\/AgoraRtcKit\/objc(pl)NSObject"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/onMediaPlayerVideoFrame(_:mediaPlayerId:)":{"navigatorTitle":[{"kind":"identifier","text":"onMediaPlayerVideoFrame:mediaPlayerId:"}],"role":"symbol","title":"onMediaPlayerVideoFrame(_:mediaPlayerId:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onMediaPlayerVideoFrame"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":", "},{"kind":"externalParam","text":"mediaPlayerId"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onMediaPlayerVideoFrame(_:mediaPlayerId:)","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/onmediaplayervideoframe(_:mediaplayerid:)"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/getRotationApplied()":{"role":"symbol","title":"getRotationApplied()","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"getRotationApplied"},{"kind":"text","text":"() -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Occurs each time the SDK receives a video frame, and prompts you whether to"},{"type":"text","text":" "},{"type":"text","text":"rotate the captured video. If the video has been rotated according to"},{"type":"text","text":" "},{"type":"text","text":"rotation in AgoraOutputVideoFrame on the capture device, you do not need to"},{"type":"text","text":" "},{"type":"text","text":"call this method to set the video rotation.This function only applies to the"},{"type":"text","text":" "},{"type":"text","text":"scenarios where the video processing mode is"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFrameProcessModeReadOnly.This function only supports video data in"},{"type":"text","text":" "},{"type":"text","text":"RGBA and YUV420."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getRotationApplied()","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"getRotationApplied"}],"url":"\/documentation\/agorartckit\/agoravideoframedelegate\/getrotationapplied()"},"doc://AgoraRtcKit/documentation/AgoraRtcKit":{"role":"collection","title":"AgoraRtcKit","abstract":[{"type":"text","text":"Summary"}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit","kind":"symbol","type":"topic","url":"\/documentation\/agorartckit"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/onTranscodedVideoFrame(_:)":{"navigatorTitle":[{"kind":"identifier","text":"onTranscodedVideoFrame:"}],"role":"symbol","title":"onTranscodedVideoFrame(_:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onTranscodedVideoFrame"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Gets the video data captured from the screen before encoding."},{"type":"text","text":" "},{"type":"text","text":"After you successfully register the video frame observer, the SDK triggers"},{"type":"text","text":" "},{"type":"text","text":"this callback each time it receives a video frame. In this callback, you can"},{"type":"text","text":" "},{"type":"text","text":"get the video data captured from the screen before encoding and then process"},{"type":"text","text":" "},{"type":"text","text":"the data according to your particular scenarios.After processing, you can"},{"type":"text","text":" "},{"type":"text","text":"send the processed video data back to the SDK in this callback.To get the"},{"type":"text","text":" "},{"type":"text","text":"video data captured from the second screen before encoding, you need to set"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFramePositionPreEncoder (1 << 2) as a frame position through"},{"type":"text","text":" "},{"type":"text","text":"getObservedFramePosition .The video data that this callback gets has been"},{"type":"text","text":" "},{"type":"text","text":"preprocessed, with its content cropped and rotated, and the image"},{"type":"text","text":" "},{"type":"text","text":"enhanced.This callback does not support sending processed RGBA video data"},{"type":"text","text":" "},{"type":"text","text":"back to the SDK."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onTranscodedVideoFrame(_:)","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/ontranscodedvideoframe(_:)"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/onRenderVideoFrame(_:uid:channelId:)":{"navigatorTitle":[{"kind":"identifier","text":"onRenderVideoFrame:uid:channelId:"}],"role":"symbol","title":"onRenderVideoFrame(_:uid:channelId:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onRenderVideoFrame"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":", "},{"kind":"externalParam","text":"uid"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"UInt","preciseIdentifier":"s:Su"},{"kind":"text","text":", "},{"kind":"externalParam","text":"channelId"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Occurs each time the SDK receives a video frame sent by the remote user."},{"type":"text","text":" "},{"type":"text","text":"After you successfully register the video frame observer, the SDK triggers"},{"type":"text","text":" "},{"type":"text","text":"this callback each time it receives a video frame. In this callback, you can"},{"type":"text","text":" "},{"type":"text","text":"get the video data sent from the remote end before rendering, and then"},{"type":"text","text":" "},{"type":"text","text":"process it according to the particular scenarios.If the video data type you"},{"type":"text","text":" "},{"type":"text","text":"get is RGBA, the SDK does not support processing the data of the alpha"},{"type":"text","text":" "},{"type":"text","text":"channel."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onRenderVideoFrame(_:uid:channelId:)","kind":"symbol","required":true,"type":"topic","url":"\/documentation\/agorartckit\/agoravideoframedelegate\/onrendervideoframe(_:uid:channelid:)"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/getVideoFormatPreference()":{"role":"symbol","title":"getVideoFormatPreference()","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"getVideoFormatPreference"},{"kind":"text","text":"() -> "},{"kind":"typeIdentifier","text":"AgoraVideoFormat","preciseIdentifier":"c:@E@AgoraVideoFormat"}],"abstract":[{"type":"text","text":"Sets the format of the raw video data output by the SDK."},{"type":"text","text":" "},{"type":"text","text":"If you want to get raw video data in a color encoding format other than YUV"},{"type":"text","text":" "},{"type":"text","text":"420, register this callback when calling setVideoFrameDelegate . After you"},{"type":"text","text":" "},{"type":"text","text":"successfully register the video frame observer, the SDK triggers this"},{"type":"text","text":" "},{"type":"text","text":"callback each time it receives a video frame. You need to set your preferred"},{"type":"text","text":" "},{"type":"text","text":"video data in the return value of this callback."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getVideoFormatPreference()","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"getVideoFormatPreference"}],"url":"\/documentation\/agorartckit\/agoravideoframedelegate\/getvideoformatpreference()"},"doc://AgoraRtcKit/documentation/AgoraRtcKit/AgoraVideoFrameDelegate/onPreEncode(_:sourceType:)":{"role":"symbol","title":"onPreEncode(_:sourceType:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"onPreEncode"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"AgoraOutputVideoFrame","preciseIdentifier":"c:objc(cs)AgoraOutputVideoFrame"},{"kind":"text","text":", "},{"kind":"externalParam","text":"sourceType"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"AgoraVideoSourceType","preciseIdentifier":"c:@E@AgoraVideoSourceType"},{"kind":"text","text":") -> "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"Occurs each time the SDK receives a video frame before encoding."},{"type":"text","text":" "},{"type":"text","text":"After you successfully register the video frame observer, the SDK triggers"},{"type":"text","text":" "},{"type":"text","text":"this callback each time it receives a video frame. In this callback, you can"},{"type":"text","text":" "},{"type":"text","text":"get the video data before encoding and then process the data according to"},{"type":"text","text":" "},{"type":"text","text":"your particular scenarios.After processing, you can send the processed video"},{"type":"text","text":" "},{"type":"text","text":"data back to the SDK in this callback.To get the video data captured from the"},{"type":"text","text":" "},{"type":"text","text":"second screen before encoding, you need to set"},{"type":"text","text":" "},{"type":"text","text":"AgoraVideoFramePositionPreEncoder (1 << 2) as a frame position through"},{"type":"text","text":" "},{"type":"text","text":"getObservedFramePosition .The video data that this callback gets has been"},{"type":"text","text":" "},{"type":"text","text":"preprocessed, with its content cropped and rotated, and the image enhanced."}],"identifier":"doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onPreEncode(_:sourceType:)","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"onPreEncodeVideoFrame:sourceType:"}],"url":"\/documentation\/agorartckit\/agoravideoframedelegate\/onpreencode(_:sourcetype:)"}},"variantOverrides":[{"patch":[{"op":"replace","path":"\/identifier\/interfaceLanguage","value":"occ"},{"op":"replace","path":"\/metadata\/roleHeading","value":"Protocol"},{"op":"replace","path":"\/metadata\/title","value":"AgoraVideoFrameDelegate"},{"op":"replace","path":"\/metadata\/symbolKind","value":"protocol"},{"op":"replace","path":"\/metadata\/fragments","value":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}]},{"op":"replace","path":"\/metadata\/navigatorTitle","value":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}]},{"op":"replace","path":"\/topicSections","value":[{"title":"Instance Methods","identifiers":["doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getMirrorApplied()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getObservedFramePosition()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getRotationApplied()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getVideoFormatPreference()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/getVideoFrameProcessMode()","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onCapture(_:sourceType:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onMediaPlayerVideoFrame(_:mediaPlayerId:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onPreEncode(_:sourceType:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onRenderVideoFrame(_:uid:channelId:)","doc:\/\/AgoraRtcKit\/documentation\/AgoraRtcKit\/AgoraVideoFrameDelegate\/onTranscodedVideoFrame(_:)"]}]},{"op":"replace","path":"\/relationshipsSections","value":[{"identifiers":["doc:\/\/AgoraRtcKit\/objc(pl)NSObject"],"kind":"relationships","title":"Inherits From","type":"inheritsFrom"}]},{"op":"add","path":"\/seeAlsoSections","value":null},{"op":"replace","path":"\/primaryContentSections\/0","value":{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"@protocol"},{"kind":"text","text":" "},{"kind":"identifier","text":"AgoraVideoFrameDelegate"},{"kind":"text","text":" <"},{"kind":"typeIdentifier","text":"NSObject","preciseIdentifier":"c:objc(pl)NSObject"},{"kind":"text","text":">"}],"languages":["occ"],"platforms":["iOS"]}]}},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getObservedFramePosition()\/title","value":"getObservedFramePosition"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getObservedFramePosition()\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"getObservedFramePosition"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getMirrorApplied()\/title","value":"getMirrorApplied"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getMirrorApplied()\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"getMirrorApplied"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getVideoFrameProcessMode()\/title","value":"getVideoFrameProcessMode"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getVideoFrameProcessMode()\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"getVideoFrameProcessMode"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onCapture(_:sourceType:)\/title","value":"onCaptureVideoFrame:sourceType:"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onCapture(_:sourceType:)\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onCaptureVideoFrame:sourceType:"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate\/title","value":"AgoraVideoFrameDelegate"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate\/fragments","value":[{"kind":"identifier","text":"AgoraVideoFrameDelegate"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onMediaPlayerVideoFrame(_:mediaPlayerId:)\/title","value":"onMediaPlayerVideoFrame:mediaPlayerId:"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onMediaPlayerVideoFrame(_:mediaPlayerId:)\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onMediaPlayerVideoFrame:mediaPlayerId:"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getRotationApplied()\/title","value":"getRotationApplied"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getRotationApplied()\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"getRotationApplied"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onTranscodedVideoFrame(_:)\/title","value":"onTranscodedVideoFrame:"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onTranscodedVideoFrame(_:)\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onTranscodedVideoFrame:"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onRenderVideoFrame(_:uid:channelId:)\/title","value":"onRenderVideoFrame:uid:channelId:"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onRenderVideoFrame(_:uid:channelId:)\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onRenderVideoFrame:uid:channelId:"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getVideoFormatPreference()\/title","value":"getVideoFormatPreference"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1getVideoFormatPreference()\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"getVideoFormatPreference"}]},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onPreEncode(_:sourceType:)\/title","value":"onPreEncodeVideoFrame:sourceType:"},{"op":"replace","path":"\/references\/doc:~1~1AgoraRtcKit~1documentation~1AgoraRtcKit~1AgoraVideoFrameDelegate~1onPreEncode(_:sourceType:)\/fragments","value":[{"kind":"text","text":"- "},{"kind":"identifier","text":"onPreEncodeVideoFrame:sourceType:"}]}],"traits":[{"interfaceLanguage":"occ"}]}]}